[
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "name": "TouchRugby",
            "version": "1.0",
            "description": "Train an Llama 3.2 MLX model to answer questions about the rules of Touch Rugby."
        },
        "model": {
            "name": "mlx-community/Llama-3.2-1B-Instruct-4bit",
            "path": "mlx-community/Llama-3.2-1B-Instruct-4bit"
        },
        "datasets": {
            "name": "Trelis/touch-rugby-rules",
            "path": "Trelis/touch-rugby-rules"
        },
        "training": {
            "type": "LoRA",
            "plugin": "mlx_lora_trainer",
            "formatting_template": "<|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n{{prompt}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n{{completion}}",
            "config_json": "{\"template_name\":\"TouchRugby\",\"plugin_name\":\"mlx_lora_trainer\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"<|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{{prompt}}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{{completion}}\",\"dataset_name\":\"Trelis/touch-rugby-rules\",\"lora_layers\":\"16\",\"batch_size\":\"4\",\"learning_rate\":\"0.0001\",\"lora_rank\":\"16\",\"lora_alpha\":\"32\",\"iters\":\"100\",\"steps_per_report\":\"10\",\"steps_per_eval\":\"16\",\"save_every\":\"10\",\"adaptor_name\":\"touch-rugby\"}"
        },
        "test": {}
    },
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "version": "0.1",
            "name": "WikiSQL",
            "description": "Trains a model to answer SQL queries. Adapted from https://github.com/ml-explore/mlx-examples/"
        },
        "model": {
            "name": "meta-llama/Llama-3.2-1B",
            "path": "meta-llama/Llama-3.2-1B"
        },
        "datasets": {
            "name": "WikiSQL",
            "path": "WikiSQL"
        },
        "training": {
            "type": "LoRA",
            "plugin": "mlx_lora_trainer",
            "formatting_template": "Given the following description of an SQL table and its columns, provide the corresponding SQL to answer the question. {{text}}",
            "config_json": "{\"template_name\":\"WikiSQL\",\"plugin_name\":\"mlx_lora_trainer\",\"model_name\":\"meta-llama/Llama-3.2-1B\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"Given the following description of an SQL table and its columns, provide the corresponding SQL to answer the question.\\n{{text}}\",\"dataset_name\":\"WikiSQL\",\"lora_layers\":\"8\",\"batch_size\":\"4\",\"learning_rate\":\"0.0001\",\"lora_rank\":\"8\",\"lora_alpha\":\"160\",\"iters\":\"200\",\"steps_per_report\":\"10\",\"steps_per_eval\":\"50\",\"save_every\":\"50\",\"adaptor_name\":\"ml-qa\"}"
        },
        "test": {}
    },
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "name": "Dialogue Summarizing",
            "version": "1.0",
            "description": "Trains Gemma base model to summarize conversations."
        },
        "model": {
            "name": "google/gemma-2b",
            "path": "google/gemma-2b"
        },
        "datasets": {
            "name": "samsum",
            "path": "samsum"
        },
        "training": {
            "type": "LoRA",
            "plugin": "sft_llama_factory",
            "formatting_template": "",
            "config_json": "{\"template_name\":\"Dialogue Summarizing\",\"plugin_name\":\"sft_llama_factory\",\"model_name\":\"google/gemma-2b\",\"model_architecture\":\"GemmaForCausalLM\",\"instruction_template\":\"Summarize the following text:\",\"input_template\":\"{{dialogue}}\",\"output_template\":\"{{summary}}\",\"dataset_name\":\"samsum\",\"maximum_sequence_length\":\"2048\",\"learning_rate\":\"0.001\",\"num_train_epochs\":\"2\",\"max_steps\":\"-1\",\"lora_r\":\"16\",\"lora_alpha\":\"32\",\"lora_dropout\":\"0.05\",\"adaptor_name\":\"summarizer\"}"
        },
        "test": {}
    },
    {
        "schemaVersion": "0.1",
        "metadata": {
            "author": "",
            "version": "1.0",
            "name": "MachineLearningQnA",
            "description": "Trains a Gemma 2 model to answer machine learning questions. Adapted from https://medium.com/tutorial-by-winston-wang/beginners-guide-to-fine-tuning-models-using-mlx-on-apple-silicon-1a21ebb70aed"
        },
        "model": {
            "name": "google/gemma-2-2b-it",
            "path": "google/gemma-2-2b-it"
        },
        "datasets": {
            "name": "Machine Learning QA Collection",
            "path": "win-wang/Machine_Learning_QA_Collection"
        },
        "training": {
            "type": "LoRA",
            "plugin": "mlx_lora_trainer",
            "formatting_template": "{{text}}",
            "config_json": "{\"template_name\":\"MachineLearningQnA\",\"plugin_name\":\"mlx_lora_trainer\",\"model_name\":\"google/gemma-2-2b-it\",\"model_architecture\":\"Gemma2ForCausalLM\",\"formatting_template\":\"{{text}}\", \"dataset_name\":\"win-wang/Machine_Learning_QA_Collection\",\"lora_layers\":\"8\",\"batch_size\":\"4\",\"learning_rate\":\"0.0001\",\"lora_rank\":\"8\",\"lora_alpha\":\"160\",\"iters\":\"200\",\"steps_per_report\":\"10\",\"steps_per_eval\":\"50\",\"save_every\":\"50\",\"adaptor_name\":\"ml-qa\"}"
        },
        "test": {}
    }
]