{
  "id": "fine_tune_existing_model",
  "title": "Fine-tune an Existing Model",
  "description": "Adapt a pre-trained model to your specific needs using LoRA. Save time and resources by leveraging existing knowledge.",
  "notes": "# Fine-Tune Qwen 2.5 for Dialogue Summarization\n\n## Overview\nThis recipe fine-tunes the **Qwen 2.5-1.5B-Instruct** model to excel at creating concise, accurate summaries of conversations and dialogues using LoRA (Low-Rank Adaptation). It includes both training and evaluation components to assess summarization performance.\n\nTo get started, simply go to the **Workflows** page and click **Run** \u2014 the entire process is automated for you.\n\n## Workflow Breakdown\nThe workflow consists of the following automated steps:\n\n1. **LoRA Fine-Tuning**  \n   The model is fine-tuned on the SAMSum dataset using LoRA adaptation, learning to generate concise summaries from dialogue transcripts.\n\n2. **Post-Training Evaluation**  \n   The fine-tuned model is evaluated on the MMLU benchmark to ensure it maintains general knowledge while gaining summarization expertise.\n\n## How to Use the Fine-Tuned Model\nOnce the training is complete, you can interact with the updated model directly:\n\n1. Go to the **Foundation** tab  \n2. Look for the model titled:  \n   `Qwen2.5-1.5B-Instruct_Summarizer`  \n3. Click **Run**  \n4. Navigate to the **Interact** tab to start chatting\n\nYou can now provide dialogues and conversations for the model to summarize effectively.\n\n## Important Notes\n- This recipe uses **LoRA fine-tuning** for efficient training with reduced memory requirements\n- Optimized for **CUDA GPU** architectures\n- Uses the **SAMSum dataset** containing diverse conversation formats and styles\n- LoRA preserves the base model's general capabilities while adding summarization expertise\n\n## Expected Outcomes\nAfter completing this recipe, your model should be able to:\n- Generate concise, accurate summaries of conversations and dialogues\n- Maintain key information and context from the original conversations\n- Handle various dialogue formats including casual chats, meetings, and structured conversations\n- Preserve general language understanding while excelling at summarization tasks\n- Provide summaries suitable for chat logs, meeting transcripts, and customer service interactions",
  "requiredMachineArchitecture": [
    "cuda"
  ],
  "dependencies": [
    {
      "type": "model",
      "name": "Qwen/Qwen2.5-1.5B-Instruct"
    },
    {
      "type": "plugin",
      "name": "llama_trainer"
    },
    {
      "type": "dataset",
      "name": "knkarthick/samsum"
    },
    {
      "type": "plugin",
      "name": "eleuther-ai-lm-evaluation-harness-mlx"
    }
  ],
  "tasks": [
    {
      "name": "finetune_model",
      "task_type": "TRAIN",
      "type": "LoRA",
      "plugin": "llama_trainer",
      "formatting_template": "Instruction: Summarize the Following\nPrompt: {{dialogue}}\nGeneration: {{summary}}",
      "config_json": "{\"template_name\":\"DialogueSummarizing\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"Qwen/Qwen2.5-1.5B-Instruct\",\"model_architecture\":\"Qwen2ForCausalLM\",\"formatting_template\":\"Instruction: Summarize the Following\\nPrompt: {{dialogue}}\\nGeneration: {{summary}}\",\"dataset_name\":\"knkarthick/samsum\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"4\",\"learning_rate\":\"0.00005\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"32\",\"lora_alpha\":\"64\",\"lora_dropout\":\"0.05\",\"adaptor_name\":\"Summarizer\"}"
    },
    {
      "name": "evaluate_finetuned",
      "task_type": "EVAL",
      "plugin": "eleuther-ai-lm-evaluation-harness-mlx",
      "config_json": "{\"template_name\":\"EvalFineTuned\",\"plugin_name\":\"eleuther-ai-lm-evaluation-harness-mlx\",\"model_name\":\"Qwen/Qwen2.5-1.5B-Instruct\",\"model_architecture\":\"Qwen2ForCausalLM\",\"tasks\":\"mmlu\",\"limit\":\"0.5\",\"run_name\":\"EvalFineTuned\"}"
    }
  ],
  "workflows": [
    {
      "name": "Finetune_and_Evaluate",
      "config": {
        "nodes": [
          {
            "id": "node_finetune",
            "type": "TRAIN",
            "task": "finetune_model",
            "name": "Fine-tuning Task",
            "out": [
              "node_eval"
            ]
          },
          {
            "id": "node_eval",
            "type": "EVAL",
            "task": "evaluate_finetuned",
            "name": "Evaluation Task",
            "out": []
          }
        ]
      }
    }
  ],
  "cardImage": "https://images.unsplash.com/photo-1561375996-8bbec3f2a481?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
}