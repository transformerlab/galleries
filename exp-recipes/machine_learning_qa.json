{
  "id": "ml_qa",
  "title": "Machine Learning Q&A",
  "description": "Train a Qwen 2.5 model to provide expert-level answers to machine learning questions, suitable for both beginners and advanced practitioners.",
  "notes": "# Fine-Tune Qwen 2.5 on Machine Learning Q&A\n\n## Overview\nThis recipe fine-tunes the **Qwen 2.5-1.5B-Instruct** model to become an expert machine learning assistant, specializing in answering questions about ML concepts, algorithms, and implementations. It uses a comprehensive dataset of machine learning Q&A pairs to create a knowledgeable ML tutor.\n\nTo get started, simply go to the **Training** page and click **Queue** \u2014 the training process is ready to run.\n\n## Training Process\nThis recipe performs LoRA fine-tuning on the Qwen 2.5 model using:\n\n1. **Model**: Qwen/Qwen2.5-1.5B-Instruct (1.5B parameter instruction-tuned model)\n2. **Dataset**: Machine Learning Q&A Collection containing diverse ML questions and detailed answers\n3. **Training Method**: LoRA (Low-Rank Adaptation) for efficient fine-tuning\n4. **Optimization**: Optimized for CUDA and AMD GPU architectures\n\n## How to Use the Fine-Tuned Model\nOnce the training is complete, you can interact with the updated model directly:\n\n1. Go to the **Foundation** tab  \n2. Look for the model titled:  \n   `Qwen2.5-1.5B-Instruct_ML-QA`  \n3. Click **Run**  \n4. Navigate to the **Interact** tab to start chatting\n\nYou can now test the model on questions about supervised learning, deep learning, model evaluation, feature engineering, and more advanced ML topics.\n\n## Important Notes\n- This recipe is optimized for **CUDA and AMD GPU** architectures\n- LoRA training allows efficient fine-tuning while preserving the base model's capabilities\n- The model balances theoretical understanding with practical implementation guidance\n- Suitable for learners at various ML expertise levels\n\n## Expected Outcomes\nAfter completing this recipe, your model should be able to:\n- Provide detailed explanations of ML concepts and algorithms\n- Answer both theoretical and practical machine learning questions\n- Guide users through complex ML topics with clear, progressive explanations\n- Offer implementation advice and best practices\n- Help with model selection, evaluation metrics, and troubleshooting",
  "requiredMachineArchitecture": [
    "cuda",
    "amd"
  ],
  "dependencies": [
    {
      "type": "model",
      "name": "Qwen/Qwen2.5-1.5B-Instruct"
    },
    {
      "type": "dataset",
      "name": "win-wang/Machine_Learning_QA_Collection"
    },
    {
      "type": "plugin",
      "name": "llama_trainer"
    }
  ],
  "tasks": [
    {
      "name": "MachineLearningQnA",
      "task_type": "TRAIN",
      "type": "LoRA",
      "plugin": "llama_trainer",
      "config_json": "{\"template_name\":\"MachineLearningQnA\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"Qwen/Qwen2.5-1.5B-Instruct\",\"model_architecture\":\"Qwen2ForCausalLM\",\"formatting_template\":\"{{text}}\\n\",\"dataset_name\":\"win-wang/Machine_Learning_QA_Collection\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"1\",\"learning_rate\":\"0.00005\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"16\",\"lora_alpha\":\"64\",\"lora_dropout\":\"0.1\",\"adaptor_name\":\"ML-QA\",\"_tlab_recipe_datasets\":{\"name\":\"win-wang/Machine_Learning_QA_Collection\",\"path\":\"win-wang/Machine_Learning_QA_Collection\"},\"_tlab_recipe_models\":{\"name\":\"Qwen/Qwen2.5-1.5B-Instruct\",\"path\":\"Qwen/Qwen2.5-1.5B-Instruct\"}}"
    }
  ],
  "workflows": [],
  "cardImage": "https://images.unsplash.com/photo-1557562645-4eee56b29bc1?q=80&w=1935&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
}