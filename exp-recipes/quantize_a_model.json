{
  "id": "quantize_model",
  "title": "Quantize a Model",
  "description": "Optimize your model for faster inference and reduced size using quantization tools.",
  "notes": "# Model Quantization\n\nThis recipe quantizes a model to reduce its size and improve inference speed while maintaining performance.\n\n## How to Use\nTo get a quantized model, simply go to the **Workflows** tab and run the `quantize-a-model-to-gguf` workflow. Once it is complete, you can go to the Model Zoo -> Generated to see your newly generated model.\n\n## What it does\n- Converts your model to GGUF format with q8_0 quantization\n- Reduces model size for faster loading\n- Maintains good performance with minimal accuracy loss",
  "requiredMachineArchitecture": ["mlx", "cuda"],
  "dependencies": [
    {
      "type": "model",
      "name": "unsloth/Llama-3.2-1B-Instruct"
    },
    {
      "type": "plugin",
      "name": "gguf_exporter"
    }
  ],
  "tasks": [
    {
      "name": "ExportGGUFTask",
      "task_type": "EXPORT",
      "plugin": "gguf_exporter",
      "config_json": "{\"plugin_name\":\"gguf_exporter\",\"input_model_id\":\"unsloth/Llama-3.2-1B-Instruct\",\"input_model_path\":\"unsloth/Llama-3.2-1B-Instruct\",\"input_model_architecture\":\"LlamaForCausalLM\",\"output_model_id\":\"Llama-3.2-1B-Instruct-1752517918-q8_0.gguf\",\"output_model_architecture\":\"GGUF\",\"output_model_name\":\"Llama-3.2-1B-Instruct - GGUF - q8_0\",\"output_model_path\":\"/models/Llama-3.2-1B-Instruct-1752517918-q8_0.gguf\",\"output_filename\":\"Llama-3.2-1B-Instruct-1752517918-q8_0.gguf\",\"script_directory\":\"/plugins/gguf_exporter\",\"params\":{\"outtype\":\"q8_0\"},\"run_name\":\"ExportGGUFTask\"}",
      "inputs_json": "{\"input_model_id\":\"unsloth/Llama-3.2-1B-Instruct\",\"input_model_path\":\"unsloth/Llama-3.2-1B-Instruct\",\"input_model_architecture\":\"LlamaForCausalLM\",\"plugin_name\":\"gguf_exporter\",\"plugin_architecture\":\"GGUF\"}"
    }
  ],
  "workflows": [
    {
      "name": "quantize-a-model-to-gguf",
      "config": {
        "nodes": [
          {
            "type": "START",
            "id": "c7d71d3e-98e2-4cd7-9c7a-dc749f2e5988",
            "name": "START",
            "out": ["05b76236-0e85-4da3-a0f1-06dc36055179"],
            "metadata": {
              "position": {
                "x": -15,
                "y": -120
              }
            }
          },
          {
            "name": "ExportTask",
            "task": "ExportGGUFTask",
            "type": "EXPORT",
            "metadata": {
              "position": {
                "x": -45,
                "y": 15
              }
            },
            "id": "05b76236-0e85-4da3-a0f1-06dc36055179",
            "out": []
          }
        ]
      }
    }
  ],
  "cardImage": "https://recipes.transformerlab.net/quantization.png"
}
