{
  "id": "answer_sql_queries_mlx",
  "title": "Answer SQL Queries using MLX",
  "description": "Fine-tune a Llama 3.2 1B model to understand and generate SQL queries, optimized for Apple Silicon using MLX framework.",
  "notes": "# Train LLaMA 3.2 for SQL Query Generation (MLX)\n\n## Overview\nThis recipe fine-tunes the **LLaMA 3.2-1B** model to understand and generate SQL queries, optimized for Apple Silicon using the MLX framework. It uses the WikiSQL dataset to train the model on diverse SQL patterns and database query scenarios.\n\nTo get started, simply go to the **Training** page and click **Queue** \u2014 the training process is ready to run.\n\n## Training Process\nThis recipe performs LoRA fine-tuning on the LLaMA 3.2 model using:\n\n1. **Model**: meta-llama/Llama-3.2-1B (efficient 1B parameter base model)\n2. **Dataset**: WikiSQL containing diverse SQL queries and database structures\n3. **Training Method**: LoRA fine-tuning optimized for SQL understanding and generation\n4. **Optimization**: MLX framework for optimal performance on Apple Silicon\n\n## How to Use the Fine-Tuned Model\nOnce the training is complete, you can interact with the updated model directly:\n\n1. Go to the **Foundation** tab  \n2. Look for the model titled:  \n   `Llama-3.2-1B_ml-qa`  \n3. Click **Run**  \n4. Navigate to the **Interact** tab to start chatting\n\nYou can now provide database descriptions and questions, and the model will generate appropriate SQL queries with explanations.\n\n## Important Notes\n- This recipe uses **MLX optimization** for Apple Silicon (M1/M2/M3) chips\n- Uses the **WikiSQL dataset** for comprehensive SQL training across diverse scenarios\n- LoRA training ensures efficient fine-tuning while preserving base model capabilities\n- The model learns to translate natural language questions into proper SQL syntax\n\n## Expected Outcomes\nAfter completing this recipe, your model should be able to:\n- Generate correct and efficient SQL queries from natural language descriptions\n- Understand database table structures and relationships\n- Handle various SQL operations including SELECT, WHERE, GROUP BY, and JOIN\n- Explain query logic and reasoning behind SQL generation\n- Work with different database scenarios and complexity levels\n- Provide practical SQL solutions for real-world database tasks",
  "requiredMachineArchitecture": [
    "mlx"
  ],
  "dependencies": [
    {
      "type": "model",
      "name": "meta-llama/Llama-3.2-1B"
    },
    {
      "type": "dataset",
      "name": "mlx-community/wikisql"
    },
    {
      "type": "plugin",
      "name": "mlx_lora_trainer"
    }
  ],
  "tasks": [
    {
      "name": "WikiSQL-MLX",
      "task_type": "TRAIN",
      "type": "LoRA",
      "plugin": "mlx_lora_trainer",
      "config_json": "{\"template_name\":\"WikiSQL-MLX\",\"plugin_name\":\"mlx_lora_trainer\",\"model_name\":\"meta-llama/Llama-3.2-1B\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"Given the following description of an SQL table and its columns, provide the corresponding SQL to answer the question.\\n{{text}}\",\"dataset_name\":\"mlx-community/wikisql\",\"lora_layers\":\"8\",\"batch_size\":\"4\",\"learning_rate\":\"0.0001\",\"lora_rank\":\"8\",\"lora_alpha\":\"160\",\"iters\":\"200\",\"steps_per_report\":\"10\",\"steps_per_eval\":\"50\",\"save_every\":\"50\",\"adaptor_name\":\"ml-qa\",\"_tlab_recipe_datasets\":{\"name\":\"mlx-community/wikisql\",\"path\":\"mlx-community/wikisql\"},\"_tlab_recipe_models\":{\"name\":\"meta-llama/Llama-3.2-1B\",\"path\":\"meta-llama/Llama-3.2-1B\"}}"
    }
  ],
  "workflows": [],
  "cardImage": "https://images.unsplash.com/photo-1683322499436-f4383dd59f5a?q=80&w=2071&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
}
