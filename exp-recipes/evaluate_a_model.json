{
  "id": 3,
  "title": "Evaluate a Model",
  "description": "Assess the performance of your model using Eleuther Labs AI Evaluation Harness. Gain insights into accuracy and reliability.",
  "notes": "# Model Evaluation\n\n## Overview\nThis recipe demonstrates how to evaluate a model's performance using the Eleuther AI Evaluation Harness.\n\n## Important Considerations\n- Uses standardized benchmarks for comparison\n- Evaluates multiple aspects of model performance\n- Provides detailed metrics and analysis\n\n## Evaluation Tips\n- Choose appropriate evaluation tasks\n- Consider using multiple benchmarks\n- Compare results with baseline models\n\n## Expected Outcomes\nThe evaluation will provide:\n- Detailed performance metrics\n- Task-specific scores\n- Comparative analysis with other models",
  "requiredMachineArchitecture": [
    "mlx"
  ],
  "dependencies": [
    {
      "type": "model",
      "name": "mlx-community/Llama-3.2-1B-Instruct-4bit"
    },
    {
      "type": "dataset",
      "name": "spencer/samsum_reformat"
    },
    {
      "type": "plugin",
      "name": "eleuther-ai-lm-evaluation-harness-mlx"
    }
  ],
  "tasks": [
    {
      "name": "evaluate_model_mmlu",
      "task_type": "EVAL",
      "plugin": "eleuther-ai-lm-evaluation-harness-mlx",
      "config_json": "{\"template_name\":\"EvalMMLU\",\"plugin_name\":\"eleuther-ai-lm-evaluation-harness-mlx\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"MLX\",\"tasks\":\"mmlu\",\"limit\":\"1.0\",\"run_name\":\"EvalMMLU\"}"
    },
    {
      "name": "evaluate_model_truthfulqa",
      "task_type": "EVAL",
      "plugin": "eleuther-ai-lm-evaluation-harness-mlx",
      "config_json": "{\"template_name\":\"EvalTruthfulQA\",\"plugin_name\":\"eleuther-ai-lm-evaluation-harness-mlx\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"MLX\",\"tasks\":\"truthfulqa\",\"limit\":\"1.0\",\"run_name\":\"EvalTruthfulQA\"}"
    }
  ],
  "workflows": [
    {
      "name": "Comprehensive_Evaluation",
      "config": {
        "nodes": [
          {
            "id": "node_eval_mmlu",
            "type": "EVAL",
            "task": "evaluate_model_mmlu",
            "name": "MMLU Evaluation",
            "out": [
              "node_eval_truthfulqa"
            ]
          },
          {
            "id": "node_eval_truthfulqa",
            "type": "EVAL",
            "task": "evaluate_model_truthfulqa",
            "name": "TruthfulQA Evaluation",
            "out": []
          }
        ]
      }
    }
  ],
  "cardImage": "https://images.unsplash.com/photo-1606326608606-aa0b62935f2b?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
}