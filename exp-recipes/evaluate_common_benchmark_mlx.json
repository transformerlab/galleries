{
  "id": "eval-common-benchmarks-mlx",
  "title": "Evaluate a Model on Common Benchmarks on MLX",
  "requiredMachineArchitecture": ["mlx"],
  "description": "Performs evaluation on common benchmarks using the Eleuther AI LM Eval Harness. It evaluates the model `mlx-community/Llama-3.2-1B-Instruct-4bit` on tasks such as Winogrande, HellaSwag, and PIQA.",
  "notes": "# Model Evaluation on Common Benchmarks (MLX)\n\nTo run this experiment, go to Evaluate in the sidebar, and click on Queue. Once it is done, click on \"Detailed Report\" or \"Chart\" to see results.\n\n## Overview\nThis recipe evaluates a Llama 3.2 model on common benchmarks using the Eleuther AI LM Eval Harness.\n\n## Expected Outcome\nAfter evaluation, you can view:\n- Detailed performance reports\n- Comparative charts and metrics\n- Benchmark scores for HellaSwag, PIQA, and Winogrande",
  "zOrder": 2,
  "dependencies": [
    {
      "type": "model",
      "name": "mlx-community/Llama-3.2-1B-Instruct-4bit"
    },
    {
      "type": "plugin",
      "name": "common-eleuther-ai-lm-eval-harness-mlx"
    }
  ],
  "tasks": [
    {
      "name": "EvalOnCommonBenchmarks",
      "task_type": "EVAL",
      "plugin": "common-eleuther-ai-lm-eval-harness-mlx",
      "config_json": "{\"template_name\":\"EvalOnCommonBenchmarks\",\"plugin_name\":\"common-eleuther-ai-lm-eval-harness-mlx\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"MLX\",\"tasks\":\"hellaswag,piqa,winogrande\",\"limit\":\"1\",\"run_name\":\"EvalOnCommonBenchmarks\",\"predefined_tasks\":\"\",\"script_parameters\":{\"template_name\":\"EvalOnCommonBenchmarks\",\"plugin_name\":\"common-eleuther-ai-lm-eval-harness-mlx\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"MLX\",\"tasks\":\"hellaswag,piqa,winogrande\",\"limit\":\"1\",\"run_name\":\"EvalOnCommonBenchmarks\",\"predefined_tasks\":\"\"}}",
      "inputs_json": "{}"
    }
  ],
  "workflows": [],
  "cardImage": "https://recipes.transformerlab.net/radialchart.png"
}
