{
  "id": "train_lora_and_evaluate_touch_rugby (NEW)",
  "title": "Train LoRA and Evaluate Touch Rugby",
  "description": "Fine-tune a Llama 3.2 1B model on Touch Rugby rules using LoRA, then evaluate its performance on common benchmarks.",
  "notes": "# Train LoRA and Evaluate Touch Rugby\n\n## Overview\nThis recipe demonstrates how to fine-tune a Llama 3.2 1B model on Touch Rugby rules using LoRA (Low-Rank Adaptation) and then evaluate the model's performance.\n\n## Getting Started\n1. Run the **TouchRugbyTrain** task first to fine-tune the model on Touch Rugby rules\n2. After training completes, run the **EvalTask** to evaluate the model's performance on MMLU, PIQA, and Winogrande benchmarks\n\n## Training Details\n- Uses LoRA for efficient fine-tuning\n- Trains on Touch Rugby rules dataset\n- Low learning rate for stable convergence\n\n## Expected Outcomes\nAfter training and evaluation, you'll have:\n- A specialized model for Touch Rugby questions\n- Performance metrics on standard benchmarks\n- Insights into model capabilities after domain-specific training",
  "requiredMachineArchitecture": ["amd", "cuda"],
  "dependencies": [
    {
      "type": "model",
      "name": "unsloth/Llama-3.2-1B-Instruct"
    },
    {
      "type": "dataset",
      "name": "Trelis/touch-rugby-rules"
    },
    {
      "type": "plugin",
      "name": "llama_trainer"
    },
    {
      "type": "plugin",
      "name": "common-eleuther-ai-lm-eval-harness"
    }
  ],
  "tasks": [
    {
      "name": "TouchRugbyTrain",
      "task_type": "TRAIN",
      "plugin": "llama_trainer",
      "config_json": "{\"template_name\":\"TouchRugbyTrain\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"foundation_model_file_path\":\"\",\"embedding_model\":\"BAAI/bge-base-en-v1.5\",\"embedding_model_architecture\":\"BertModel\",\"embedding_model_file_path\":\"\",\"formatting_template\":\"Instruction: Summarize the Following\\nPrompt: {{dialogue}}\\nGeneration: {{summary}}\",\"dataset_name\":\"Trelis/touch-rugby-rules\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"4\",\"learning_rate_schedule\":\"constant\",\"learning_rate\":\"0.00005\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"16\",\"lora_alpha\":\"32\",\"lora_dropout\":\"0.05\",\"adaptor_name\":\"touch-rugby\",\"log_to_wandb\":\"on\",\"fuse_model\":\"on\",\"sweep_config\":\"{}\",\"run_sweeps\":false,\"type\":\"LoRA\"}"
    },
    {
      "name": "EvalTask",
      "task_type": "EVAL",
      "plugin": "common-eleuther-ai-lm-eval-harness",
      "config_json": "{\"template_name\":\"EvalTask\",\"plugin_name\":\"common-eleuther-ai-lm-eval-harness\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"tasks\":\"mmlu,piqa,winogrande\",\"limit\":\"1\",\"run_name\":\"EvalTask\",\"predefined_tasks\":\"\",\"script_parameters\":{\"template_name\":\"EvalTask\",\"plugin_name\":\"common-eleuther-ai-lm-eval-harness\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"tasks\":\"mmlu,piqa,winogrande\",\"limit\":\"1\",\"run_name\":\"EvalTask\",\"predefined_tasks\":\"\"}}"
    }
  ],
  "workflows": [],
  "cardImage": ""
}