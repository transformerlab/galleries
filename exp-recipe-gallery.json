[
    {
        "id": "answer_sql_queries",
        "title": "Answer SQL Queries",
        "description": "Train a Qwen 2.5 model to excel at SQL query generation, understanding, and optimization across various database scenarios.",
        "notes": "# SQL Query Assistant with Qwen 2.5\n\n## Overview\nThis recipe fine-tunes a Qwen 2.5 model to become a specialized SQL query assistant.\n\n## Important Considerations\n- Comprehensive SQL knowledge base\n- Focus on query optimization\n- Covers various SQL dialects\n\n## Training Tips\n- Balance between simple and complex queries\n- Test query correctness\n- Validate across different database types\n\n## Expected Outcomes\nAfter training, the model should be able to:\n- Write efficient SQL queries\n- Explain query optimization\n- Handle complex database operations",
        "requiredMachineArchitecture": [
            "cuda",
            "amd"
        ],
        "dependencies": [
            {
                "type": "model",
                "name": "Qwen/Qwen2.5-1.5B-Instruct"
            },
            {
                "type": "dataset",
                "name": "mlx-community/wikisql"
            },
            {
                "type": "plugin",
                "name": "llama_trainer"
            }
        ],
        "tasks": [
            {
                "name": "WikiSQL",
                "task_type": "TRAIN",
                "type": "LoRA",
                "plugin": "llama_trainer",
                "config_json": "{\"template_name\":\"Wiki SQL\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"Qwen/Qwen2.5-1.5B-Instruct\",\"model_architecture\":\"Qwen2ForCausalLM\",\"formatting_template\":\"{{text}} ;\",\"dataset_name\":\"mlx-community/wikisql\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"1\",\"learning_rate\":\"0.005\",\"num_train_epochs\":\"2\",\"max_steps\":\"-1\",\"lora_r\":\"32\",\"lora_alpha\":\"64\",\"lora_dropout\":\"0.1\",\"adaptor_name\":\"WikiSQL\",\"_tlab_recipe_datasets\":{\"name\":\"mlx-community/wikisql\",\"path\":\"mlx-community/wikisql\"},\"_tlab_recipe_models\":{\"name\":\"Qwen/Qwen2.5-1.5B-Instruct\",\"path\":\"Qwen/Qwen2.5-1.5B-Instruct\"}}"
            }
        ],
        "workflows": [],
        "cardImage": "https://images.unsplash.com/photo-1683322499436-f4383dd59f5a?q=80&w=2071&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    },
    {
        "id": "dialogue_summarizing",
        "title": "Dialogue Summarizing",
        "description": "Fine-tune a TinyLlama model to create concise, accurate summaries of conversations and dialogues. Perfect for chat logs, meeting transcripts, and customer service interactions.",
        "notes": "# Dialogue Summarization with TinyLlama\n\n## Overview\nThis recipe demonstrates how to fine-tune a TinyLlama model specifically for dialogue summarization using the SAMSum dataset.\n\n## Important Considerations\n- TinyLlama is optimized for efficiency while maintaining good performance\n- Uses LoRA for memory-efficient fine-tuning\n- Dataset contains diverse conversation styles and formats\n\n## Training Tips\n- Monitor the quality of generated summaries\n- Balance between brevity and information retention\n- Pay attention to maintaining conversation context\n\n## Expected Outcomes\nAfter training, the model should be able to:\n- Generate concise summaries of conversations\n- Maintain key points and context\n- Handle various dialogue formats and styles",
        "requiredMachineArchitecture": [
            "cuda",
            "amd"
        ],
        "dependencies": [
            {
                "type": "model",
                "name": "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
            },
            {
                "type": "dataset",
                "name": "knkarthick/samsum"
            },
            {
                "type": "plugin",
                "name": "llama_trainer"
            }
        ],
        "tasks": [
            {
                "name": "train_tinyllama_summarizer",
                "task_type": "TRAIN",
                "type": "LoRA",
                "plugin": "llama_trainer",
                "formatting_template": "Instruction: Summarize the Following\nPrompt: {{dialogue}}\nGeneration: {{summary}}",
                "config_json": "{\"template_name\":\"DialogueSummarizing\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"Instruction: Summarize the Following\\nPrompt: {{dialogue}}\\nGeneration: {{summary}}\",\"dataset_name\":\"knkarthick/samsum\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"4\",\"learning_rate\":\"0.00005\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"32\",\"lora_alpha\":\"64\",\"lora_dropout\":\"0.05\",\"adaptor_name\":\"Summarizer\",\"_tlab_recipe_datasets\":{\"name\":\"knkarthick/samsum\",\"path\":\"knkarthick/samsum\"},\"_tlab_recipe_models\":{\"name\":\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\"path\":\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"}}"
            }
        ],
        "workflows": [],
        "cardImage": "https://images.unsplash.com/photo-1590650046871-92c887180603?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    },
    {
        "id": "eval-common-benchmarks-non-mlx",
        "title": "Evaluate a Model on Common Benchmarks on MLX",
        "requiredMachineArchitecture": [
            "mlx"
        ],
        "description": "Performs evaluation on common benchmarks using the Eleuther AI LM Eval Harness. It evaluates the model `mlx-community/Llama-3.2-1B-Instruct-4bit` on tasks such as Winogrande, HellaSwag, and PIQA.",
        "notes": "In this simple eval experiment, we set up some common evaluations against\nthe open source mlx-community/Llama-3.2-1B-Instruct-4bit model.\n\nTo run it, go to Evaluate in the sidebar, and click on Queue. Once it is done, click on\n\"Detailed Report\" or \"Chart\" to see results.",
        "zOrder": 2,
        "dependencies": [
            {
                "type": "model",
                "name": "mlx-community/Llama-3.2-1B-Instruct-4bit"
            },
            {
                "type": "plugin",
                "name": "common-eleuther-ai-lm-eval-harness-mlx"
            }
        ],
        "tasks": [
            {
                "name": "EvalOnCommonBenchmarks",
                "task_type": "EVAL",
                "plugin": "common-eleuther-ai-lm-eval-harness-mlx",
                "config_json": "{\"template_name\":\"EvalOnCommonBenchmarks\",\"plugin_name\":\"common-eleuther-ai-lm-eval-harness-mlx\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"MLX\",\"tasks\":\"hellaswag,piqa,winogrande\",\"limit\":\"1\",\"run_name\":\"EvalOnCommonBenchmarks\",\"predefined_tasks\":\"\",\"script_parameters\":{\"template_name\":\"EvalOnCommonBenchmarks\",\"plugin_name\":\"common-eleuther-ai-lm-eval-harness-mlx\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"MLX\",\"tasks\":\"hellaswag,piqa,winogrande\",\"limit\":\"1\",\"run_name\":\"EvalOnCommonBenchmarks\",\"predefined_tasks\":\"\"}}"
            }
        ],
        "workflows": [
            {
                "name": "eval-on-common-benchmarks",
                "config": {
                    "nodes": [
                        {
                            "type": "START",
                            "id": "99b97abd-82de-4745-b64a-6540801261c1",
                            "name": "START",
                            "out": [
                                "06334a95-01c4-4ece-82fc-9a107a4036e2"
                            ]
                        },
                        {
                            "name": "Eval on Harness Benchmarks",
                            "task": "EvalOnCommonBenchmarks",
                            "type": "EVAL",
                            "metadata": {
                                "position": {
                                    "x": -75,
                                    "y": 105
                                }
                            },
                            "id": "06334a95-01c4-4ece-82fc-9a107a4036e2",
                            "out": []
                        }
                    ]
                }
            }
        ],
        "cardImage": "https://recipes.transformerlab.net/radialchart.png"
    },
    {
        "id": "eval-common-benchmarks-non-mlx",
        "title": "Evaluate a Model on Common Benchmarks",
        "requiredMachineArchitecture": [
            "cuda",
            "amd"
        ],
        "description": "Performs evaluation on common benchmarks using the Eleuther AI LM Eval Harness. It evaluates the model `unsloth/Llama-3.2-1B-Instruct` on tasks such as MMLU, Winogrande, HellaSwag, and PIQA.",
        "notes": "",
        "dependencies": [
            {
                "type": "model",
                "name": "unsloth/Llama-3.2-1B-Instruct"
            },
            {
                "type": "plugin",
                "name": "common-eleuther-ai-lm-eval-harness"
            }
        ],
        "tasks": [
            {
                "name": "KindMoose",
                "task_type": "EVAL",
                "plugin": "common-eleuther-ai-lm-eval-harness",
                "config_json": "{\"template_name\":\"KindMoose\",\"plugin_name\":\"common-eleuther-ai-lm-eval-harness\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"tasks\":\"mmlu,winogrande,hellaswag,piqa\",\"limit\":\"1\",\"run_name\":\"KindMoose\",\"predefined_tasks\":\"\",\"script_parameters\":{\"template_name\":\"KindMoose\",\"plugin_name\":\"common-eleuther-ai-lm-eval-harness\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"tasks\":\"mmlu,winogrande,hellaswag,piqa\",\"limit\":\"1\",\"run_name\":\"KindMoose\",\"predefined_tasks\":\"\"}}"
            }
        ],
        "workflows": [
            {
                "name": "evaluate-on-common-benchmarks",
                "config": {
                    "nodes": [
                        {
                            "type": "START",
                            "id": "bc9dc3a4-afba-4956-a55f-bd51e96da24f",
                            "name": "START",
                            "out": [
                                "009309fa-1ed5-42bc-be5d-b84e32772bf1"
                            ]
                        },
                        {
                            "name": "EVAL HARNESS",
                            "task": "KindMoose",
                            "type": "EVAL",
                            "metadata": {
                                "position": {
                                    "x": -60,
                                    "y": 75
                                }
                            },
                            "id": "009309fa-1ed5-42bc-be5d-b84e32772bf1",
                            "out": []
                        }
                    ]
                }
            }
        ],
        "cardImage": "https://images.unsplash.com/photo-1589595427524-2ddaf2d43fc9?q=80&w=1744&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    },
    {
        "id": "fine_tune_small_mlx",
        "title": "Fine Tune a Small Language Model using MLX",
        "description": "Train a Llama 3.2 1B model to understand and answer questions about Touch Rugby rules using the MLX framework. Perfect for rule-based question answering.",
        "notes": "# MLX Fine-Tuning Notes\n\n## Overview\nThis recipe fine-tunes a Llama 3.2 1B model specifically for Touch Rugby rules using the MLX framework.\n\n## Important Considerations\n- MLX is optimized for Apple Silicon (M1/M2/M3 chips)\n- The dataset contains Touch Rugby rules in Q&A format\n- Model size is kept small (1B parameters) for efficient inference\n\n## Training Tips\n- Monitor loss curves carefully\n- Use appropriate LoRA rank (typically 8-64)\n- Validate on unseen rugby scenarios\n\n## Expected Outcomes\nAfter training, the model should be able to answer questions about:\n- Touch Rugby rules and regulations\n- Game procedures and scoring\n- Player positions and responsibilities",
        "requiredMachineArchitecture": [
            "mlx"
        ],
        "zOrder": 1,
        "dependencies": [
            {
                "type": "model",
                "name": "mlx-community/Llama-3.2-1B-Instruct-4bit"
            },
            {
                "type": "plugin",
                "name": "mlx_lora_trainer"
            },
            {
                "type": "dataset",
                "name": "Trelis/touch-rugby-rules"
            },
            {
                "type": "plugin",
                "name": "common-eleuther-ai-lm-eval-harness-mlx"
            },
            {
                "type": "plugin",
                "name": "synthesizer_scratch"
            }
        ],
        "tasks": [
            {
                "name": "fine_tune_touch_rugby",
                "task_type": "TRAIN",
                "type": "LoRA",
                "plugin": "mlx_lora_trainer",
                "formatting_template": "{{prompt}}\n{{completion}}",
                "config_json": "{\"template_name\":\"TouchRugby\",\"plugin_name\":\"mlx_lora_trainer\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"{{prompt}}\\n{{completion}}\",\"dataset_name\":\"Trelis/touch-rugby-rules\",\"lora_layers\":\"16\",\"batch_size\":\"8\",\"learning_rate\":\"0.0001\",\"lora_rank\":\"32\",\"lora_alpha\":\"128\",\"iters\":\"120\",\"steps_per_report\":\"10\",\"steps_per_eval\":\"20\",\"save_every\":\"10\",\"adaptor\":\"touch-rugby\"}"
            },
            {
                "name": "evaluate_touch_rugby",
                "task_type": "EVAL",
                "plugin": "common-eleuther-ai-lm-eval-harness-mlx",
                "config_json": "{\"template_name\":\"HandsomeBadger\",\"plugin_name\":\"common-eleuther-ai-lm-eval-harness-mlx\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"MLX\",\"tasks\":\"mmlu\",\"limit\":\"0.5\",\"run_name\":\"HandsomeBadger\",\"predefined_tasks\":\"\",\"script_parameters\":{\"template_name\":\"HandsomeBadger\",\"plugin_name\":\"common-eleuther-ai-lm-eval-harness-mlx\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"MLX\",\"tasks\":\"mmlu\",\"limit\":\"0.5\",\"run_name\":\"HandsomeBadger\",\"predefined_tasks\":\"\"}}"
            },
            {
                "name": "generate_touch_rugby_examples",
                "task_type": "GENERATE",
                "plugin": "synthesizer_scratch",
                "config_json": "{\"template_name\":\"SparklingNarwhal\",\"plugin_name\":\"synthesizer_scratch\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"MLX\",\"generation_model\":\"local\",\"num_goldens\":\"51\",\"generate_expected_output\":\"Yes\",\"scenario\":\"You are an expert in Touch Rugby rules and regulations. Generate diverse training examples that cover various aspects of the game.\",\"task\":\"Create question-answer pairs about Touch Rugby rules, focusing on game procedures, scoring rules, player positions, and common scenarios.\",\"input_format\":\"A specific question about Touch Rugby rules, formatted as: Question: [question text].\",\"expected_output_format\":\"A clear, accurate answer explaining the relevant Touch Rugby rule, formatted as: Answer: [detailed explanation]\",\"run_name\":\"SparklingNarwhal\",\"generation_type\":\"scratch\",\"script_parameters\":{\"template_name\":\"SparklingNarwhal\",\"plugin_name\":\"synthesizer_scratch\",\"model_name\":\"mlx-community/Llama-3.2-1B-Instruct-4bit\",\"model_architecture\":\"MLX\",\"generation_model\":\"local\",\"num_goldens\":\"51\",\"generate_expected_output\":\"Yes\",\"scenario\":\"You are an expert in Touch Rugby rules and regulations. Generate diverse training examples that cover various aspects of the game.\",\"task\":\"Create question-answer pairs about Touch Rugby rules, focusing on game procedures, scoring rules, player positions, and common scenarios.\",\"input_format\":\"A specific question about Touch Rugby rules, formatted as: Question: [question text].\",\"expected_output_format\":\"A clear, accurate answer explaining the relevant Touch Rugby rule, formatted as: Answer: [detailed explanation]\",\"run_name\":\"SparklingNarwhal\",\"generation_type\":\"scratch\"}}"
            }
        ],
        "workflows": [
            {
                "name": "Workflow_1",
                "config": {
                    "nodes": [
                        {
                            "id": "node_train",
                            "type": "TRAIN",
                            "task": "fine_tune_touch_rugby",
                            "name": "Training Task",
                            "out": [
                                "node_eval"
                            ]
                        },
                        {
                            "id": "node_eval",
                            "type": "EVAL",
                            "task": "evaluate_touch_rugby",
                            "name": "Evaluation Task",
                            "out": [
                                "node_generate"
                            ]
                        },
                        {
                            "id": "node_generate",
                            "type": "GENERATE",
                            "task": "generate_touch_rugby_examples",
                            "name": "Generation Task",
                            "out": []
                        }
                    ]
                }
            }
        ],
        "cardImage": "https://images.unsplash.com/photo-1558151507-c1aa3d917dbb?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    },
    {
        "id": "fine_tune_existing_model",
        "title": "Fine-tune an Existing Model",
        "description": "Adapt a pre-trained model to your specific needs using LoRA. Save time and resources by leveraging existing knowledge.",
        "notes": "# What This Recipe Does\n\nThis recipe compares a base model's performance before and after fine-tuning on touch rugby data:\n\n1. **Generate Base Model Outputs** - Creates responses using the original model\n2. **Evaluate Base Model** - Measures quality using ROUGE scores\n3. **Fine-tune with LoRA** - Trains the model on touch rugby rules (efficient training method)\n4. **Generate Fine-tuned Outputs** - Creates responses using the trained adaptor\n5. **Evaluate Fine-tuned Model** - Measures improved quality\n\n## How to Use\n1. Go to the **Workflows** tab and run the \"fine_tune_model\" workflow\n2. Wait for all steps to complete\n3. Switch to the **Evaluate** tab to see the comparison results\n\n## What You'll Learn\n- How much fine-tuning improves performance on your specific domain\n- The difference between base model and fine-tuned model outputs",
        "requiredMachineArchitecture": [
            "cuda",
            "amd"
        ],
        "dependencies": [
            {
                "type": "model",
                "name": "unsloth/Llama-3.2-1B-Instruct"
            },
            {
                "type": "dataset",
                "name": "Trelis/touch-rugby-rules"
            },
            {
                "type": "plugin",
                "name": "llama_trainer"
            },
            {
                "type": "plugin",
                "name": "deepeval_objective"
            },
            {
                "type": "dataset",
                "name": "transformerlab/touch-rugby-evals"
            },
            {
                "type": "plugin",
                "name": "batched_generation_datasets"
            }
        ],
        "tasks": [
            {
                "name": "BrilliantBaboon",
                "task_type": "TRAIN",
                "plugin": "llama_trainer",
                "config_json": "{\"template_name\":\"BrilliantBaboon\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"foundation_model_file_path\":\"\",\"embedding_model\":\"BAAI/bge-base-en-v1.5\",\"embedding_model_architecture\":\"BertModel\",\"embedding_model_file_path\":\"\",\"formatting_template\":\"{{prompt}}\\n{{completion}}\",\"dataset_name\":\"Trelis/touch-rugby-rules\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"4\",\"learning_rate_schedule\":\"constant\",\"learning_rate\":\"0.00005\",\"num_train_epochs\":\"200\",\"max_steps\":\"-1\",\"lora_r\":\"4\",\"lora_alpha\":\"8\",\"lora_dropout\":\"0.05\",\"adaptor_name\":\"touch-rugby-rules\",\"log_to_wandb\":\"true\",\"fuse_model\":\"true\",\"sweep_config\":\"{}\",\"run_sweeps\":false,\"type\":\"LoRA\"}"
            },
            {
                "name": "EvalFineTunedRugby",
                "task_type": "EVAL",
                "plugin": "deepeval_objective",
                "config_json": "{\"template_name\":\"EvalFineTunedRugby\",\"plugin_name\":\"deepeval_objective\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"model_adapter\":\"touch-rugby-rules\",\"limit\":\"1\",\"dataset_split\":\"train\",\"tasks\":\"Rouge\",\"dataset_name\":\"finetuned_rugby_outputs\",\"_dataset_display_message\":\"Please upload a dataset file with columns: 'input', 'output', 'expected_output'. The context column is optional if using metrics which don't require it.\",\"run_name\":\"EvalFineTunedRugby\",\"predefined_tasks\":\"\",\"script_parameters\":{\"template_name\":\"EvalFineTunedRugby\",\"plugin_name\":\"deepeval_objective\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"model_adapter\":\"touch-rugby-rules\",\"limit\":\"1\",\"dataset_split\":\"train\",\"tasks\":\"Rouge\",\"dataset_name\":\"finetuned_rugby_outputs\",\"_dataset_display_message\":\"Please upload a dataset file with columns: 'input', 'output', 'expected_output'. The context column is optional if using metrics which don't require it.\",\"run_name\":\"EvalFineTunedRugby\",\"predefined_tasks\":\"\"}}"
            },
            {
                "name": "EvalBaseModel",
                "task_type": "EVAL",
                "plugin": "deepeval_objective",
                "config_json": "{\"template_name\":\"EvalBaseModel\",\"plugin_name\":\"deepeval_objective\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"model_adapter\":\"touch-rugby-rules\",\"limit\":\"1\",\"dataset_split\":\"train\",\"tasks\":\"Rouge\",\"dataset_name\":\"base_rugby_outputs\",\"_dataset_display_message\":\"Please upload a dataset file with columns: 'input', 'output', 'expected_output'. The context column is optional if using metrics which don't require it.\",\"run_name\":\"EvalBaseModel\",\"predefined_tasks\":\"\",\"script_parameters\":{\"template_name\":\"EvalBaseModel\",\"plugin_name\":\"deepeval_objective\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"model_adapter\":\"touch-rugby-rules\",\"limit\":\"1\",\"dataset_split\":\"train\",\"tasks\":\"Rouge\",\"dataset_name\":\"base_rugby_outputs\",\"_dataset_display_message\":\"Please upload a dataset file with columns: 'input', 'output', 'expected_output'. The context column is optional if using metrics which don't require it.\",\"run_name\":\"EvalBaseModel\",\"predefined_tasks\":\"\"}}"
            },
            {
                "name": "TrainedAdaptorOutputs",
                "task_type": "GENERATE",
                "plugin": "batched_generation_datasets",
                "config_json": "{\"template_name\":\"TrainedAdaptorOutputs\",\"plugin_name\":\"batched_generation_datasets\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"model_adapter\":\"touch-rugby-rules\",\"generation_model\":\"Local\",\"system_prompt\":\"Answer in terms of touch rugby\",\"input_column\":\"input\",\"output_column\":\"output\",\"batch_size\":\"128\",\"temperature\":\"0.7\",\"top_p\":\"1\",\"max_tokens\":\"1024\",\"dataset_split\":\"train\",\"output_dataset_name\":\"finetuned_rugby_outputs\",\"dataset_name\":\"transformerlab/touch-rugby-evals\",\"_dataset_display_message\":\"Please upload a dataset file with columns: 'input', 'output', 'expected_output'. The context column is optional if using metrics which don't require it.\",\"run_name\":\"TrainedAdaptorOutputs\",\"generation_type\":\"scratch\",\"script_parameters\":{\"template_name\":\"TrainedAdaptorOutputs\",\"plugin_name\":\"batched_generation_datasets\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"model_adapter\":\"touch-rugby-rules\",\"generation_model\":\"Local\",\"system_prompt\":\"Answer in terms of touch rugby\",\"input_column\":\"input\",\"output_column\":\"output\",\"batch_size\":\"128\",\"temperature\":\"0.7\",\"top_p\":\"1\",\"max_tokens\":\"1024\",\"dataset_split\":\"train\",\"output_dataset_name\":\"finetuned_rugby_outputs\",\"dataset_name\":\"transformerlab/touch-rugby-evals\",\"_dataset_display_message\":\"Please upload a dataset file with columns: 'input', 'output', 'expected_output'. The context column is optional if using metrics which don't require it.\",\"run_name\":\"TrainedAdaptorOutputs\",\"generation_type\":\"scratch\"}}"
            },
            {
                "name": "BaseModelOutputs",
                "task_type": "GENERATE",
                "plugin": "batched_generation_datasets",
                "config_json": "{\"template_name\":\"BaseModelOutputs\",\"plugin_name\":\"batched_generation_datasets\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"model_adapter\":\"\",\"generation_model\":\"Local\",\"system_prompt\":\"Answer in terms of touch rugby\",\"input_column\":\"input\",\"output_column\":\"output\",\"batch_size\":\"128\",\"temperature\":\"0.7\",\"top_p\":\"1\",\"max_tokens\":\"1024\",\"dataset_split\":\"train\",\"output_dataset_name\":\"base_rugby_outputs\",\"dataset_name\":\"transformerlab/touch-rugby-evals\",\"_dataset_display_message\":\"Please upload a dataset file with columns: 'input', 'output', 'expected_output'. The context column is optional if using metrics which don't require it.\",\"run_name\":\"BaseModelOutputs\",\"generation_type\":\"scratch\",\"script_parameters\":{\"template_name\":\"BaseModelOutputs\",\"plugin_name\":\"batched_generation_datasets\",\"model_name\":\"unsloth/Llama-3.2-1B-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"model_adapter\":\"\",\"generation_model\":\"Local\",\"system_prompt\":\"Answer in terms of touch rugby\",\"input_column\":\"input\",\"output_column\":\"output\",\"batch_size\":\"128\",\"temperature\":\"0.7\",\"top_p\":\"1\",\"max_tokens\":\"1024\",\"dataset_split\":\"train\",\"output_dataset_name\":\"base_rugby_outputs\",\"dataset_name\":\"transformerlab/touch-rugby-evals\",\"_dataset_display_message\":\"Please upload a dataset file with columns: 'input', 'output', 'expected_output'. The context column is optional if using metrics which don't require it.\",\"run_name\":\"BaseModelOutputs\",\"generation_type\":\"scratch\"}}"
            }
        ],
        "workflows": [
            {
                "name": "fine_tune_model",
                "config": {
                    "nodes": [
                        {
                            "type": "START",
                            "id": "b157b5ea-8778-486a-a94f-fef2cad1d07b",
                            "name": "START",
                            "out": [
                                "1b290a1e-aab3-494c-9502-dff4460db4b7"
                            ],
                            "metadata": {
                                "position": {
                                    "x": -30,
                                    "y": -150
                                }
                            }
                        },
                        {
                            "name": "GenerateBaseOutputs",
                            "task": "BaseModelOutputs",
                            "type": "GENERATE",
                            "metadata": {
                                "position": {
                                    "x": -90,
                                    "y": -75
                                }
                            },
                            "id": "1b290a1e-aab3-494c-9502-dff4460db4b7",
                            "out": [
                                "6e5ade62-1163-4e60-9fe5-38ed36adc6a9"
                            ]
                        },
                        {
                            "name": "EvalBaseOutputs",
                            "task": "EvalBaseModel",
                            "type": "EVAL",
                            "metadata": {
                                "position": {
                                    "x": -90,
                                    "y": 45
                                }
                            },
                            "id": "6e5ade62-1163-4e60-9fe5-38ed36adc6a9",
                            "out": [
                                "969ef1ac-0e66-4f72-85a9-c4a9d08fa0fc"
                            ]
                        },
                        {
                            "name": "TrainTouchRugbyRules",
                            "task": "BrilliantBaboon",
                            "type": "TRAIN",
                            "metadata": {
                                "position": {
                                    "x": -90,
                                    "y": 195
                                }
                            },
                            "id": "969ef1ac-0e66-4f72-85a9-c4a9d08fa0fc",
                            "out": [
                                "53d4a815-6ef8-47cd-b341-24ae233c4c04"
                            ]
                        },
                        {
                            "name": "GenerateTrainedAdaptorOutputs",
                            "task": "TrainedAdaptorOutputs",
                            "type": "GENERATE",
                            "metadata": {
                                "position": {
                                    "x": -105,
                                    "y": 330
                                }
                            },
                            "id": "53d4a815-6ef8-47cd-b341-24ae233c4c04",
                            "out": [
                                "1e4e9270-4ac8-4870-a6e4-21fe04684f51"
                            ]
                        },
                        {
                            "name": "EvalTrainedAdaptor",
                            "task": "EvalFineTunedRugby",
                            "type": "EVAL",
                            "metadata": {
                                "position": {
                                    "x": -90,
                                    "y": 480
                                }
                            },
                            "id": "1e4e9270-4ac8-4870-a6e4-21fe04684f51",
                            "out": []
                        }
                    ]
                }
            }
        ],
        "cardImage": "https://images.unsplash.com/photo-1561375996-8bbec3f2a481?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    },
    {
        "id": "ml_qa",
        "title": "Machine Learning Q&A",
        "description": "Train a Qwen 2.5 model to provide expert-level answers to machine learning questions, suitable for both beginners and advanced practitioners.",
        "notes": "# Machine Learning Q&A with Qwen 2.5\n\n## Overview\nThis recipe fine-tunes a Qwen 2.5 model to become a specialized machine learning assistant.\n\n## Important Considerations\n- Comprehensive ML knowledge coverage\n- Balanced between theoretical and practical knowledge\n- Suitable for various ML expertise levels\n\n## Training Tips\n- Focus on explanation clarity\n- Balance technical depth with accessibility\n- Validate answers across ML domains\n\n## Expected Outcomes\nAfter training, the model should be able to:\n- Provide detailed ML explanations\n- Answer implementation questions\n- Guide through ML concepts progressively",
        "requiredMachineArchitecture": [
            "cuda",
            "amd"
        ],
        "dependencies": [
            {
                "type": "model",
                "name": "Qwen/Qwen2.5-1.5B-Instruct"
            },
            {
                "type": "dataset",
                "name": "win-wang/Machine_Learning_QA_Collection"
            },
            {
                "type": "plugin",
                "name": "llama_trainer"
            }
        ],
        "tasks": [
            {
                "name": "MachineLearningQnA",
                "task_type": "TRAIN",
                "type": "LoRA",
                "plugin": "llama_trainer",
                "config_json": "{\"template_name\":\"MachineLearningQnA\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"Qwen/Qwen2.5-1.5B-Instruct\",\"model_architecture\":\"Qwen2ForCausalLM\",\"formatting_template\":\"{{text}}\\n\",\"dataset_name\":\"win-wang/Machine_Learning_QA_Collection\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"1\",\"learning_rate\":\"0.00005\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"16\",\"lora_alpha\":\"64\",\"lora_dropout\":\"0.1\",\"adaptor_name\":\"ML-QA\",\"_tlab_recipe_datasets\":{\"name\":\"win-wang/Machine_Learning_QA_Collection\",\"path\":\"win-wang/Machine_Learning_QA_Collection\"},\"_tlab_recipe_models\":{\"name\":\"Qwen/Qwen2.5-1.5B-Instruct\",\"path\":\"Qwen/Qwen2.5-1.5B-Instruct\"}}"
            }
        ],
        "workflows": [],
        "cardImage": "https://images.unsplash.com/photo-1557562645-4eee56b29bc1?q=80&w=1935&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    },
    {
        "id": "python_code_completion",
        "title": "Python Code Completion",
        "description": "Train a SmolLM Base model to provide intelligent Python code completions, suggestions, and assistance. Ideal for developers looking for an efficient coding assistant.",
        "notes": "# Python Code Completion Training\n\n## Overview\nThis recipe fine-tunes a SmolLM Base model to become a specialized Python code completion assistant.\n\n## Important Considerations\n- SmolLM is designed for efficient inference\n- Dataset contains diverse Python coding examples\n- Model learns common Python patterns and best practices\n\n## Training Tips\n- Focus on code context understanding\n- Balance between common and specialized completions\n- Monitor completion accuracy and relevance\n\n## Expected Outcomes\nAfter training, the model should be able to:\n- Provide context-aware code completions\n- Suggest appropriate Python syntax\n- Complete common programming patterns",
        "requiredMachineArchitecture": [
            "cuda",
            "amd"
        ],
        "dependencies": [
            {
                "type": "model",
                "name": "HuggingFaceTB/SmolLM2-135M"
            },
            {
                "type": "dataset",
                "name": "flytech/python-codes-25k"
            },
            {
                "type": "plugin",
                "name": "llama_trainer"
            }
        ],
        "tasks": [
            {
                "name": "train_smollm_python_completion",
                "task_type": "TRAIN",
                "type": "LoRA",
                "plugin": "llama_trainer",
                "formatting_template": "{{output}}",
                "config_json": "{\"template_name\":\"PythonCompletion\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"HuggingFaceTB/SmolLM2-135M\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"{{output}}\\n\",\"dataset_name\":\"flytech/python-codes-25k\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"4\",\"learning_rate\":\"0.0005\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"64\",\"lora_alpha\":\"128\",\"lora_dropout\":\"0.05\",\"adaptor_name\":\"python\",\"_tlab_recipe_datasets\":{\"name\":\"flytech/python-codes-25k\",\"path\":\"flytech/python-codes-25k\"},\"_tlab_recipe_models\":{\"name\":\"HuggingFaceTB/SmolLM2-135M\",\"path\":\"HuggingFaceTB/SmolLM2-135M\"}}"
            }
        ],
        "workflows": [],
        "cardImage": "https://images.unsplash.com/photo-1515879218367-8466d910aaa4?q=80&w=2069&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    },
    {
        "id": "quantize_model",
        "title": "Quantize a Model",
        "description": "Optimize your model for faster inference and reduced size using quantization tools.",
        "notes": "# Model Quantization\n\nThis recipe quantizes a model to reduce its size and improve inference speed while maintaining performance.\n\n## How to Use\nTo get a quantized model, simply go to the **Workflows** tab and run the `quantize-a-model-to-gguf` workflow.\n\n## What it does\n- Converts your model to GGUF format with q8_0 quantization\n- Reduces model size for faster loading\n- Maintains good performance with minimal accuracy loss",
        "requiredMachineArchitecture": [
            "mlx",
            "cuda"
        ],
        "dependencies": [
            {
                "type": "model",
                "name": "unsloth/Llama-3.2-1B-Instruct"
            },
            {
                "type": "plugin",
                "name": "gguf_exporter"
            }
        ],
        "tasks": [
            {
                "name": "Export_Llama-3.2-1B-Instruct_to_GGUF",
                "task_type": "EXPORT",
                "plugin": "gguf_exporter",
                "config_json": "{\"plugin_name\":\"gguf_exporter\",\"input_model_id\":\"unsloth/Llama-3.2-1B-Instruct\",\"input_model_path\":\"unsloth/Llama-3.2-1B-Instruct\",\"input_model_architecture\":\"LlamaForCausalLM\",\"output_model_id\":\"Llama-3.2-1B-Instruct-1752245303-q8_0.gguf\",\"output_model_architecture\":\"GGUF\",\"output_model_name\":\"Llama-3.2-1B-Instruct - GGUF - q8_0\",\"output_model_path\":\"/models/Llama-3.2-1B-Instruct-1752245303-q8_0.gguf\",\"output_filename\":\"Llama-3.2-1B-Instruct-1752245303-q8_0.gguf\",\"script_directory\":\"/plugins/gguf_exporter\",\"params\":{\"outtype\":\"q8_0\"}}"
            }
        ],
        "workflows": [
            {
                "name": "quantize-a-model-to-gguf",
                "config": {
                    "nodes": [
                        {
                            "type": "START",
                            "id": "c7d71d3e-98e2-4cd7-9c7a-dc749f2e5988",
                            "name": "START",
                            "out": [
                                "40f0c960-c9c7-4be0-a8a3-7fc8e5c6e443"
                            ],
                            "metadata": {
                                "position": {
                                    "x": -15,
                                    "y": -120
                                }
                            }
                        },
                        {
                            "name": "EXPORT Model",
                            "task": "Export_Llama-3.2-1B-Instruct_to_GGUF",
                            "type": "EXPORT",
                            "metadata": {
                                "position": {
                                    "x": -45,
                                    "y": -15
                                }
                            },
                            "id": "40f0c960-c9c7-4be0-a8a3-7fc8e5c6e443",
                            "out": []
                        }
                    ]
                }
            }
        ],
        "cardImage": "https://recipes.transformerlab.net/quantization.png"
    },
    {
        "id": "conversational_intelligence",
        "title": "Train a Model to be Conversationally Intelligent",
        "description": "Enhance a SmolLM model with advanced conversational abilities and structured response formatting using XML tags, ideal for creating a sophisticated dialogue agent.",
        "notes": "# Conversational Intelligence Training\n\n## Overview\nThis recipe develops a SmolLM model into a sophisticated conversational agent using structured dialogue formats.\n\n## Important Considerations\n- XML-based response structuring\n- Focus on natural dialogue flow\n- Balanced conversation handling\n\n## Training Tips\n- Monitor response coherence\n- Validate XML format consistency\n- Test conversation flow\n\n## Expected Outcomes\nAfter training, the model should be able to:\n- Maintain structured conversations\n- Generate well-formatted responses\n- Handle diverse dialogue scenarios",
        "requiredMachineArchitecture": [
            "cuda",
            "amd"
        ],
        "dependencies": [
            {
                "type": "model",
                "name": "HuggingFaceTB/SmolLM2-135M"
            },
            {
                "type": "dataset",
                "name": "nickrosh/Evol-Instruct-Code-80k-v1"
            },
            {
                "type": "plugin",
                "name": "llama_trainer"
            }
        ],
        "tasks": [
            {
                "name": "InstructTuning",
                "task_type": "TRAIN",
                "type": "LoRA",
                "plugin": "llama_trainer",
                "config_json": "{\"template_name\":\"InstructTuning\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"HuggingFaceTB/SmolLM2-135M\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"<User>\\n{{instruction}}\\n</User>\\n<Assistant>\\n{{output}}\\n</Assistant>\\n\",\"dataset_name\":\"nickrosh/Evol-Instruct-Code-80k-v1\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"4\",\"learning_rate\":\"0.00003\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"4\",\"lora_alpha\":\"16\",\"lora_dropout\":\"0.05\",\"adaptor_name\":\"instruct\",\"_tlab_recipe_datasets\":{\"name\":\"nickrosh/Evol-Instruct-Code-80k-v1\",\"path\":\"nickrosh/Evol-Instruct-Code-80k-v1\"},\"_tlab_recipe_models\":{\"name\":\"HuggingFaceTB/SmolLM2-135M\",\"path\":\"HuggingFaceTB/SmolLM2-135M\"}}"
            }
        ],
        "workflows": [],
        "cardImage": "https://images.unsplash.com/photo-1573497620053-ea5300f94f21?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    },
    {
        "id": "pirate_speech",
        "title": "Train a Model to Speak like a Pirate",
        "description": "Transform a SmolLM model into a charismatic pirate conversationalist, perfect for creating engaging and entertaining interactions with a nautical twist.",
        "notes": "# Pirate Speech Transformation\n\n## Overview\nThis recipe transforms a SmolLM model into an engaging pirate-speaking assistant using specialized dialogue data.\n\n## Important Considerations\n- Maintains coherent pirate-style speech\n- Balances authenticity with understandability\n- Preserves helpful responses in pirate style\n\n## Training Tips\n- Monitor consistency of pirate speech\n- Balance entertainment with usefulness\n- Maintain appropriate language level\n\n## Expected Outcomes\nAfter training, the model should be able to:\n- Respond in consistent pirate dialect\n- Maintain helpful information delivery\n- Create engaging pirate-themed interactions",
        "requiredMachineArchitecture": [
            "cuda",
            "amd"
        ],
        "dependencies": [
            {
                "type": "model",
                "name": "HuggingFaceTB/SmolLM-135M-Instruct"
            },
            {
                "type": "dataset",
                "name": "Peyton3995/dolly-15k-mistral-pirate"
            },
            {
                "type": "plugin",
                "name": "llama_trainer"
            }
        ],
        "tasks": [
            {
                "name": "PirateSpeech",
                "task_type": "TRAIN",
                "type": "LoRA",
                "plugin": "llama_trainer",
                "config_json": "{\"template_name\":\"PirateSpeech\",\"plugin_name\":\"llama_trainer\",\"model_name\":\"HuggingFaceTB/SmolLM-135M-Instruct\",\"model_architecture\":\"LlamaForCausalLM\",\"formatting_template\":\"<instruction>\\n{{instruction}}\\n</instruction>\\n<response>\\n{{response}}\\n</response>\",\"dataset_name\":\"Peyton3995/dolly-15k-mistral-pirate\",\"maximum_sequence_length\":\"2048\",\"batch_size\":\"4\",\"learning_rate_schedule\":\"cosine\",\"learning_rate\":\"0.01\",\"num_train_epochs\":\"1\",\"max_steps\":\"-1\",\"lora_r\":\"64\",\"lora_alpha\":\"128\",\"lora_dropout\":\"0.05\",\"adaptor_name\":\"Pirate_Speech\",\"_tlab_recipe_datasets\":{\"name\":\"Peyton3995/dolly-15k-mistral-pirate\",\"path\":\"Peyton3995/dolly-15k-mistral-pirate\"},\"_tlab_recipe_models\":{\"name\":\"HuggingFaceTB/SmolLM-135M-Instruct\",\"path\":\"HuggingFaceTB/SmolLM-135M-Instruct\"}}"
            }
        ],
        "workflows": [],
        "cardImage": "https://images.unsplash.com/photo-1652447275071-4bf852aebdc5?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    }
]