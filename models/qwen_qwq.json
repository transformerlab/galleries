[
  {
    "uniqueID": "Qwen/QwQ-32B",
    "name": "Qwen QwQ 32B",
    "description": "QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems.",
    "added": "2025-03-25",
    "tags": [
      "Reasoning"
    ],
    "parameters": "32B",
    "context": "40960",
    "architecture": "Qwen2ForCausalLM",
    "formats": [
      "Safetensors"
    ],
    "huggingface_repo": "Qwen/QwQ-32B",
    "transformers_version": "4.43.1",
    "gated": false,
    "license": "apache-2.0",
    "logo": "https://cdn-avatars.huggingface.co/v1/production/uploads/62088594a5943c8a8fc94560/y5SEKiE8TkjBKs9xfjCx5.png",
    "size_of_model_in_mb": 62501.64478683472,
    "author": {
      "name": "Qwen",
      "url": "https://huggingface.co/Qwen/QwQ-32B",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/Qwen/QwQ-32B",
      "downloadUrl": "https://huggingface.co/Qwen/QwQ-32B",
      "paperUrl": "?"
    },
    "model_group": "qwen"
  },
  {
    "uniqueID": "mlx-community/QwQ-32B-4bit",
    "name": "Qwen QwQ 32B (MLX 4bit)",
    "description": "MLX-formatted version of Qwen's QwQ model quantized to 4 bits.",
    "added": "2025-03-25",
    "tags": [
      "Reasoning"
    ],
    "parameters": "32B",
    "context": "131072",
    "architecture": "Qwen2ForCausalLM",
    "formats": [
      "Safetensors"
    ],
    "huggingface_repo": "mlx-community/QwQ-32B-4bit",
    "transformers_version": "4.43.1",
    "gated": false,
    "license": "apache-2.0",
    "logo": "https://cdn-avatars.huggingface.co/v1/production/uploads/62088594a5943c8a8fc94560/y5SEKiE8TkjBKs9xfjCx5.png",
    "size_of_model_in_mb": 17591.31551837921,
    "author": {
      "name": "mlx-community",
      "url": "https://huggingface.co/mlx-community/QwQ-32B-4bit",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/mlx-community/QwQ-32B-4bit",
      "downloadUrl": "https://huggingface.co/mlx-community/QwQ-32B-4bit",
      "paperUrl": "?"
    },
    "model_group": "qwen"
  },
  {
    "uniqueID": "Qwen/QwQ-32B-GGUF",
    "name": "QwQ 32B (GGUF Q4_K_M)",
    "description": "GGUF formatted version of Qwen's QwQ model quantized to 4-bits.",
    "added": "2025-03-25",
    "tags": [
      "Reasoning"
    ],
    "parameters": "32B",
    "context": "131072",
    "architecture": "Qwen2ForCausalLM",
    "formats": [
      "GGUF"
    ],
    "huggingface_repo": "Qwen/QwQ-32B-GGUF",
    "huggingface_filename": "qwq-32b-q4_k_m.gguf",
    "transformers_version": "4.43.1",
    "gated": false,
    "license": "apache-2.0",
    "logo": "https://cdn-avatars.huggingface.co/v1/production/uploads/62088594a5943c8a8fc94560/y5SEKiE8TkjBKs9xfjCx5.png",
    "size_of_model_in_mb": 20377.6,
    "author": {
      "name": "Qwen",
      "url": "https://huggingface.co/Qwen/QwQ-32B-GGUF",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/Qwen/QwQ-32B-GGUF",
      "downloadUrl": "https://huggingface.co/Qwen/QwQ-32B-GGUF",
      "paperUrl": "?"
    },
    "model_group": "qwen"
  }
]