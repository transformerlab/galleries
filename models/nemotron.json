[
  {
    "uniqueID": "nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1",
    "name": "Llama-3.1-Nemotron-Nano-4B-v1.1",
    "description": "Offers a great tradeoff between model accuracy and efficiency. The model fits on a single RTX GPU and can be used locally",
    "added": "2025-05-24",
    "tags": ["Reasoning", "RAG"],
    "parameters": "4B",
    "context": "131072",
    "architecture": "LlamaForCausalLM",
    "formats": [
      "Safetensors"
    ],
    "huggingface_repo": "nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1",
    "transformers_version": "4.47.1",
    "gated": false,
    "license": "other",
    "logo": "https://upload.wikimedia.org/wikipedia/commons/a/ab/Meta-Logo.png",
    "size_of_model_in_mb": 8623.903450965881,
    "author": {
      "name": "nvidia",
      "url": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1",
      "downloadUrl": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-4B-v1.1",
      "paperUrl": "?"
    },
    "model_group": "nemotron"
  },
  {
    "uniqueID": "nvidia/Llama-3.1-Nemotron-Nano-8B-v1",
    "name": "Llama-3.1-Nemotron-Nano-8B-v1",
    "description": "Offers a great tradeoff between model accuracy and efficiency. The model fits on a single RTX GPU and can be used locally",
    "added": "2025-05-24",
    "tags": ["Reasoning", "RAG"],
    "parameters": "8B",
    "context": "131072",
    "architecture": "LlamaForCausalLM",
    "formats": [
      "Safetensors"
    ],
    "huggingface_repo": "nvidia/Llama-3.1-Nemotron-Nano-8B-v1",
    "transformers_version": "4.47.1",
    "gated": false,
    "license": "other",
    "logo": "https://upload.wikimedia.org/wikipedia/commons/a/ab/Meta-Logo.png",
    "size_of_model_in_mb": 15333.027109146118,
    "author": {
      "name": "nvidia",
      "url": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-8B-v1",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-8B-v1",
      "downloadUrl": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-8B-v1",
      "paperUrl": "?"
    },
    "model_group": "nemotron"
  },
  {
    "uniqueID": "nvidia/AceReason-Nemotron-1.1-7B",
    "name": "AceReason-Nemotron-1.1-7B",
    "description": "A math and code reasoning model built upon the Qwen2.5-Math-7B base. The model is first trained with supervised fine-tuning on math and code tasks, then further enhanced through reinforcement learning.",
    "added": "2025-06-19",
    "tags": ["Reasoning", "Math", "Coding"],
    "parameters": "7B",
    "context": "131072",
    "architecture": "Qwen2ForCausalLM",
    "formats": [
      "Safetensors"
    ],
    "huggingface_repo": "nvidia/AceReason-Nemotron-1.1-7B",
    "transformers_version": "4.48.2",
    "gated": false,
    "license": "other",
    "logo": "https://cdn-avatars.huggingface.co/v1/production/uploads/62088594a5943c8a8fc94560/y5SEKiE8TkjBKs9xfjCx5.png",
    "size_of_model_in_mb": 14539.249306678772,
    "author": {
      "name": "nvidia",
      "url": "https://huggingface.co/nvidia/AceReason-Nemotron-1.1-7B",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/nvidia/AceReason-Nemotron-1.1-7B",
      "downloadUrl": "https://huggingface.co/nvidia/AceReason-Nemotron-1.1-7B",
      "paperUrl": "?"
    },
    "model_group": "nemotron"
  }
]