uniqueID: "HuggingFaceH4/zephyr-7b-alpha"
name: "Zephyr 7b Alpha"
description: "Zephyr is a series of language models that are trained to act as helpful assistants. Zephyr-7B-Î± is the first model in the series, and is a fine-tuned version of mistralai/Mistral-7B-v0.1 that was trained on on a mix of publicly available, synthetic datasets using Direct Preference Optimization (DPO)."
parameters: "7B"
tags:
- RAG
context: "4k"
architecture: "MistralForCausalLM"
formats: ["PyTorch"]
huggingface_repo: "HuggingFaceH4/zephyr-7b-alpha"
transformers_version: "4.34.0"
gated: "auto"
license: "MIT"
logo: "https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha/resolve/main/thumbnail.png"
size_of_model_in_mb: 27627.48
author:
  name: "HuggingFace H4"
  url: "https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha"
  blurb: ""
resources:
  canonicalUrl: "https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha"
  downloadUrl: "https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha"
  paperUrl: "?"
