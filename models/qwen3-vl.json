[
  {
    "uniqueID": "Qwen/Qwen3-VL-8B-Thinking",
    "name": "Qwen3-VL-8B-Thinking",
    "description": "8B parameter version of Qwen 3's vision-language model, specifically trained with reasoning capabilities.",
    "added": "2025-10-29",
    "tags": ["Multimodal", "Vision"],
    "parameters": "8B",
    "context": "262144",
    "architecture": "Qwen3VLForConditionalGeneration",
    "formats": [
      "Safetensors"
    ],
    "huggingface_repo": "Qwen/Qwen3-VL-8B-Thinking",
    "transformers_version": "4.57.0.dev0",
    "gated": false,
    "license": "apache-2.0",
    "logo": "https://cdn-avatars.huggingface.co/v1/production/uploads/62088594a5943c8a8fc94560/y5SEKiE8TkjBKs9xfjCx5.png",
    "size_of_model_in_mb": 16731.48652935028,
    "author": {
      "name": "Qwen",
      "url": "https://huggingface.co/Qwen/Qwen3-VL-8B-Thinking",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/Qwen/Qwen3-VL-8B-Thinking",
      "downloadUrl": "https://huggingface.co/Qwen/Qwen3-VL-8B-Thinking",
      "paperUrl": "?"
    },
    "model_group": ""
  },
  {
    "uniqueID": "Qwen/Qwen3-VL-8B-Instruct",
    "name": "Qwen3-VL-8B-Instruct",
    "description": "8B parameter version of Qwen 3's vision-language model, without reasoning post-training.",
    "added": "2025-10-29",
    "tags": ["Multimodal", "Vision"],
    "parameters": "8B",
    "context": "262144",
    "architecture": "Qwen3VLForConditionalGeneration",
    "formats": [
      "Safetensors"
    ],
    "huggingface_repo": "Qwen/Qwen3-VL-8B-Instruct",
    "transformers_version": "4.57.0.dev0",
    "gated": false,
    "license": "apache-2.0",
    "logo": "https://cdn-avatars.huggingface.co/v1/production/uploads/62088594a5943c8a8fc94560/y5SEKiE8TkjBKs9xfjCx5.png",
    "size_of_model_in_mb": 16731.486694335938,
    "author": {
      "name": "Qwen",
      "url": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct",
      "downloadUrl": "https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct",
      "paperUrl": "?"
    },
    "model_group": ""
  },
  {
    "uniqueID": "Qwen/Qwen3-VL-2B-Instruct",
    "name": "Qwen3-VL-2B-Instruct",
    "description": "2B parameter version of Qwen 3's vision-language model, without reasoning post-training",
    "added": "2025-10-29",
    "tags": ["Multimodal", "Vision"],
    "parameters": "2B",
    "context": "262144",
    "architecture": "Qwen3VLForConditionalGeneration",
    "formats": [
      "Safetensors"
    ],
    "huggingface_repo": "Qwen/Qwen3-VL-2B-Instruct",
    "transformers_version": "4.57.0.dev0",
    "gated": false,
    "license": "apache-2.0",
    "logo": "https://cdn-avatars.huggingface.co/v1/production/uploads/62088594a5943c8a8fc94560/y5SEKiE8TkjBKs9xfjCx5.png",
    "size_of_model_in_mb": 4067.390887260437,
    "author": {
      "name": "Qwen",
      "url": "https://huggingface.co/Qwen/Qwen3-VL-2B-Instruct",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/Qwen/Qwen3-VL-2B-Instruct",
      "downloadUrl": "https://huggingface.co/Qwen/Qwen3-VL-2B-Instruct",
      "paperUrl": "?"
    },
    "model_group": ""
  },
  {
    "uniqueID": "Qwen/Qwen3-VL-2B-Thinking",
    "name": "Qwen3-VL-2B-Thinking",
    "description": "2B parameter version of Qwen 3's vision-language model, specifically trained with reasoning capabilities.",
    "added": "2025-10-29",
    "tags": ["Multimodal", "Vision"],
    "parameters": "2B",
    "context": "262144",
    "architecture": "Qwen3VLForConditionalGeneration",
    "formats": [
      "Safetensors"
    ],
    "huggingface_repo": "Qwen/Qwen3-VL-2B-Thinking",
    "transformers_version": "4.57.0.dev0",
    "gated": false,
    "license": "apache-2.0",
    "logo": "https://cdn-avatars.huggingface.co/v1/production/uploads/62088594a5943c8a8fc94560/y5SEKiE8TkjBKs9xfjCx5.png",
    "size_of_model_in_mb": 4067.3907175064087,
    "author": {
      "name": "Qwen",
      "url": "https://huggingface.co/Qwen/Qwen3-VL-2B-Thinking",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/Qwen/Qwen3-VL-2B-Thinking",
      "downloadUrl": "https://huggingface.co/Qwen/Qwen3-VL-2B-Thinking",
      "paperUrl": "?"
    },
    "model_group": ""
  },
  {
    "uniqueID": "Qwen/Qwen3-VL-30B-A3B-Thinking",
    "name": "Qwen3-VL-30B-A3B-Thinking",
    "description": "30B parameter MoE version of Qwen 3's vision-language model, built on a mixture-of-experts architecture and trained with reasoning capabilities.",
    "added": "2025-10-29",
    "tags": ["Multimodal", "Vision"],
    "parameters": "30B",
    "context": "262144",
    "architecture": "Qwen3VLMoeForConditionalGeneration",
    "formats": [
      "Safetensors"
    ],
    "huggingface_repo": "Qwen/Qwen3-VL-30B-A3B-Thinking",
    "transformers_version": "4.57.0.dev0",
    "gated": false,
    "license": "apache-2.0",
    "logo": "https://cdn-avatars.huggingface.co/v1/production/uploads/62088594a5943c8a8fc94560/y5SEKiE8TkjBKs9xfjCx5.png",
    "size_of_model_in_mb": 59272.31492614746,
    "author": {
      "name": "Qwen",
      "url": "https://huggingface.co/Qwen/Qwen3-VL-30B-A3B-Thinking",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/Qwen/Qwen3-VL-30B-A3B-Thinking",
      "downloadUrl": "https://huggingface.co/Qwen/Qwen3-VL-30B-A3B-Thinking",
      "paperUrl": "?"
    },
    "model_group": ""
  },
  {
    "uniqueID": "Qwen/Qwen3-VL-30B-A3B-Instruct",
    "name": "Qwen3-VL-30B-A3B-Instruct",
    "description": "30B parameter MoE version of Qwen 3's vision-language model, built on a mixture-of-experts architecture.",
    "added": "2025-10-29",
    "tags": ["Multimodal", "Vision"],
    "parameters": "30B",
    "context": "262144",
    "architecture": "Qwen3VLMoeForConditionalGeneration",
    "formats": [
      "Safetensors"
    ],
    "huggingface_repo": "Qwen/Qwen3-VL-30B-A3B-Instruct",
    "transformers_version": "4.57.0.dev0",
    "gated": false,
    "license": "apache-2.0",
    "logo": "https://cdn-avatars.huggingface.co/v1/production/uploads/62088594a5943c8a8fc94560/y5SEKiE8TkjBKs9xfjCx5.png",
    "size_of_model_in_mb": 59272.31508922577,
    "author": {
      "name": "Qwen",
      "url": "https://huggingface.co/Qwen/Qwen3-VL-30B-A3B-Instruct",
      "blurb": ""
    },
    "resources": {
      "canonicalUrl": "https://huggingface.co/Qwen/Qwen3-VL-30B-A3B-Instruct",
      "downloadUrl": "https://huggingface.co/Qwen/Qwen3-VL-30B-A3B-Instruct",
      "paperUrl": "?"
    },
    "model_group": ""
  }
]