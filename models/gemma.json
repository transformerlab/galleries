[
    {
        "uniqueID": "google/gemma-7b",
        "name": "Gemma 7B",
        "archived": true,
        "description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants. Gemma models are well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as a laptop, desktop or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.",
        "parameters": "7B",
        "context": "8192",
        "architecture": "GemmaForCausalLM",
        "formats": [
            "Safetensors"
        ],
        "huggingface_repo": "google/gemma-7b",
        "transformers_version": "4.38.0.dev0",
        "license": "Gemma",
        "gated": "manual",
        "logo": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1200.format-webp.webp",
        "size_of_model_in_mb": 16305.17,
        "author": {
            "name": "Google",
            "url": "https://huggingface.co/google/gemma-7b",
            "blurb": ""
        },
        "resources": {
            "canonicalUrl": "https://huggingface.co/google/gemma-7b",
            "downloadUrl": "https://huggingface.co/google/gemma-7b",
            "paperUrl": "?"
        },
        "group": "gemma"
    },
    {
        "uniqueID": "google/gemma-7b-it",
        "name": "Gemma 7B Instruct",
        "archived": true,
        "description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants. Gemma models are well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as a laptop, desktop or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.",
        "parameters": "7B",
        "context": "8192",
        "architecture": "GemmaForCausalLM",
        "formats": [
            "Safetensors"
        ],
        "huggingface_repo": "google/gemma-7b-it",
        "transformers_version": "4.38.0.dev0",
        "license": "Gemma",
        "gated": "manual",
        "logo": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1200.format-webp.webp",
        "size_of_model_in_mb": 16305.17,
        "author": {
            "name": "Google",
            "url": "https://huggingface.co/google/gemma-7b-it",
            "blurb": ""
        },
        "resources": {
            "canonicalUrl": "https://huggingface.co/google/gemma-7b-it",
            "downloadUrl": "https://huggingface.co/google/gemma-7b-it",
            "paperUrl": "?"
        },
        "group": "gemma"
    },
    {
        "uniqueID": "google/gemma-2b-it",
        "name": "Gemma 2B Instruct",
        "archived": true,
        "description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants. Gemma models are well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as a laptop, desktop or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.",
        "parameters": "2B",
        "context": "8192",
        "architecture": "GemmaForCausalLM",
        "formats": [
            "Safetensors"
        ],
        "huggingface_repo": "google/gemma-2b-it",
        "transformers_version": "4.38.0.dev0",
        "license": "Gemma",
        "gated": "manual",
        "logo": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1200.format-webp.webp",
        "size_of_model_in_mb": 4800.96,
        "author": {
            "name": "Google",
            "url": "https://huggingface.co/google/gemma-2b-it",
            "blurb": ""
        },
        "resources": {
            "canonicalUrl": "https://huggingface.co/google/gemma-2b-it",
            "downloadUrl": "https://huggingface.co/google/gemma-2b-it",
            "paperUrl": "?"
        },
        "group": "gemma"
    },
    {
        "uniqueID": "google/gemma-2b",
        "name": "Gemma 2B",
        "archived": true,
        "description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants. Gemma models are well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as a laptop, desktop or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.",
        "parameters": "2B",
        "context": "8192",
        "architecture": "GemmaForCausalLM",
        "formats": [
            "Safetensors"
        ],
        "huggingface_repo": "google/gemma-2b",
        "transformers_version": "4.38.0.dev0",
        "license": "Gemma",
        "gated": "manual",
        "logo": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1200.format-webp.webp",
        "size_of_model_in_mb": 4800.96,
        "author": {
            "name": "Google",
            "url": "https://huggingface.co/google/gemma-2b",
            "blurb": ""
        },
        "resources": {
            "canonicalUrl": "https://huggingface.co/google/gemma-2b",
            "downloadUrl": "https://huggingface.co/google/gemma-2b",
            "paperUrl": "?"
        },
        "group": "gemma"
    }
]