uniqueID: Llama-3.2-1B-Instruct-Q6_K.gguf
name: LLama 3.2 1B Instruct (GGUF Q6_K)
description: 'GGUF export of Llama 3.2 1B Instruct model using 6-bit K-quantization. Should maintain near perfect results to original model.'
added: '2024-11-21'
parameters: '1B'
context: '131072'
architecture: GGUF
formats:
- GGUF
huggingface_repo: bartowski/Llama-3.2-1B-Instruct-GGUF
huggingface_filename: 'Llama-3.2-1B-Instruct-Q6_K.gguf'
gated: false
license: llama3.2
logo: 'https://upload.wikimedia.org/wikipedia/commons/a/ab/Meta-Logo.png'
size_of_model_in_mb: 1044
author:
  name: Meta
  url: 'https://huggingface.co/meta-llama/'
  blurb: ''
resources:
  canonicalUrl: https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF
  downloadUrl: https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF
  paperUrl: '?'
model_group: llama