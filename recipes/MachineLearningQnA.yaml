schemaVersion: '0.1'
metadata:
  author: ''
  version: '1.0'
  name: MachineLearningQnA
  description: 'Trains a Gemma 2 model to answer machine learning questions. Adapted from https://medium.com/tutorial-by-winston-wang/beginners-guide-to-fine-tuning-models-using-mlx-on-apple-silicon-1a21ebb70aed'
model:
  name: google/gemma-2-2b-it
  path: google/gemma-2-2b-it
datasets:
  name: Machine Learning QA Collection
  path: win-wang/Machine_Learning_QA_Collection
training:
  type: LoRA
  plugin: mlx_lora_trainer
  formatting_template: '{{text}}'
  config_json: '{"template_name":"MachineLearningQnA","plugin_name":"mlx_lora_trainer","model_name":"google/gemma-2-2b-it","model_architecture":"Gemma2ForCausalLM","formatting_template":"{{text}}",
    "dataset_name":"win-wang/Machine_Learning_QA_Collection","lora_layers":"8","batch_size":"4","learning_rate":"0.0001","lora_rank":"8","lora_alpha":"160","iters":"200","steps_per_report":"10","steps_per_eval":"50","save_every":"50","adaptor_name":"ml-qa"}'
test: {}
