[
    {
        "title": "Evaluation Task Example",
        "description": "A sample evaluation task that runs an evaluation script and creates reports.",
        "github_repo_url": "https://github.com/transformerlab/transformerlab-app",
        "github_repo_dir": "lab-sdk",
        "config": {
            "name": "demo-eval-task",
            "cluster_name": "demo-eval-task",
            "command": "cd ~/lab-sdk/scripts/examples && python fake_evals.py;",
            "cpus": "2",
            "memory": "4",
            "setup": "uv pip install transformerlab datasets;"
        },
        "metadata": {
            "category": "eval",
            "modality": "text",
            "framework": [
                "huggingface"
            ]
        }
    },
    {
        "title": "LLM Evaluation (EleutherAI)",
        "description": "Evaluates an LLM using the EleutherAI LM Evaluation Harness. Defaults to Qwen2.5-0.5B on HellaSwag and ARC-Easy benchmarks.",
        "github_repo_url": "https://github.com/transformerlab/transformerlab-examples",
        "github_repo_dir": "llm-eval-task",
        "metadata": {
            "category": "evaluation",
            "modality": "text",
            "framework": [
                "eleuther"
            ]
        }
    },
    {
        "title": "AutoTrain SFT Training",
        "description": "SFT training task using Hugging Face AutoTrain. Requires a Hugging Face token in HF_TOKEN env var for model access.",
        "github_repo_url": "https://github.com/transformerlab/transformerlab-examples",
        "github_repo_dir": "autotrain-sft",
        "metadata": {
            "category": "finetuning",
            "modality": "text",
            "framework": [
                "huggingface"
            ]
        }
    },
    {
        "title": "Unsloth LLM Fine-tuning",
        "description": "LLM training task using Unsloth FastLanguageModel with LoRA fine-tuning. Requires a Hugging Face token in HF_TOKEN env var for model access.",
        "github_repo_url": "https://github.com/transformerlab/transformerlab-examples",
        "github_repo_dir": "unsloth-llm-train",
        "metadata": {
            "category": "finetuning",
            "modality": "text",
            "framework": [
                "unsloth"
            ]
        }
    },
    {
        "title": "Unsloth GRPO Training Task",
        "description": "A GRPO trainer based on the unsloth grpo training notebooks for training models with reasoning capabilities.",
        "github_repo_url": "https://github.com/transformerlab/transformerlab-examples",
        "github_repo_dir": "unsloth-grpo-train",
        "metadata": {
            "category": "training",
            "modality": "text",
            "framework": [
                "unsloth"
            ]
        }
    },
    {
        "title": "SDXL Image Generation",
        "description": "Generates images using Stable Diffusion XL",
        "github_repo_url": "https://github.com/transformerlab/transformerlab-examples",
        "github_repo_dir": "sdxl-gen-task",
        "metadata": {
            "category": "generate",
            "modality": "image",
            "framework": [
                "stability-ai"
            ]
        }
    },
    {
        "title": "Sample Task Example",
        "description": "A sample PyTorch training task that clones a repository and runs training script",
        "github_repo_url": "https://github.com/transformerlab/transformerlab-app.git",
        "github_repo_dir": "lab-sdk",
        "config": {
            "name": "sample-task",
            "cluster_name": "sample-task",
            "command": "echo hello",
            "cpus": "2",
            "memory": "4",
            "setup": "uv pip install wandb"
        },
        "metadata": {
            "category": "other",
            "modality": "other",
            "framework": []
        }
    },
    {
        "title": "Dataset Generation Task Example",
        "description": "A sample dataset generation task that runs a dataset generation script and creates a dataset.",
        "github_repo_url": "https://github.com/transformerlab/transformerlab-app",
        "github_repo_dir": "lab-sdk",
        "config": {
            "name": "demo-generate-task",
            "cluster_name": "demo-generate-task",
            "command": "cd ~/lab-sdk/scripts/examples && python fake_dataset_generate.py;",
            "cpus": "2",
            "memory": "4",
            "setup": "uv pip install transformerlab datasets;"
        },
        "metadata": {
            "category": "dataset-generation",
            "modality": "other",
            "framework": []
        }
    },
    {
        "title": "YOLO Object Detection Train Task Example",
        "description": "A sample YOLO object detection train task that runs a YOLO object detection train script on COCO8 dataset for 10 epochs",
        "github_repo_url": "https://github.com/transformerlab/transformerlab-app/",
        "github_repo_dir": "lab-sdk",
        "config": {
            "name": "yolo-train-task",
            "cluster_name": "yolo-train-task",
            "command": "cd ~/lab-sdk/scripts/examples && python yolo_train_script.py",
            "cpus": "2",
            "memory": "4",
            "accelerators": "RTX3090:1",
            "setup": "uv pip install datasets transformers torch wandb ultralytics transformerlab;\nsudo apt update;\nsudo apt install -y libgl1 libglib2.0-0;"
        },
        "metadata": {
            "category": "training",
            "modality": "vision",
            "framework": [
                "yolo"
            ]
        }
    },
    {
        "title": "HF Training with Evals",
        "description": "A task to train a language model using the TRL library on a specified dataset with evaluation done using the EleutherAI Harness.",
        "github_repo_url": "https://github.com/transformerlab/transformerlab-examples",
        "github_repo_dir": "trl-training-evals",
        "metadata": {
            "category": "finetuning",
            "modality": "text",
            "framework": [
                "huggingface"
            ]
        }
    }
]